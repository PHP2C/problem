### 键空间
```text
本质： 还是订阅发布
目的： 为了减少数据库I/O，批量写入数据
```
看下php代码：

```php
<?php
const select1 = 6;
function redis_conn() {
    // 具体细节不必多说
    return (new \Redis())->connect('127.0.0.1');
}
$redis = redis_conn();// redis 连接就不必细说

/**
 * Subscribe to channels by pattern
 *
 * @param array                 $patterns an array of glob-style patterns to subscribe
 * @param string|array|callable $callback Either a string or an array with an object and method.
 *                     The callback will get four arguments ($redis, $pattern, $channel, $message)
 * @return mixed|Redis Any non-null return value in the callback will be returned to the caller or Redis if in multimode
 *
 * @throws RedisException
 *
 * @link    https://redis.io/commands/psubscribe
 * @example
 * <pre>
 * function f($redis, $pattern, $chan, $msg) {
 *  echo "Pattern: $pattern\n";
 *  echo "Channel: $chan\n";
 *  echo "Payload: $msg\n";
 * }
 *
 * $redis->psubscribe(array('chan-1', 'chan-2', 'chan-3'), 'f')
 * </pre>
 */
$call_back = function($redis, $pattern, $chan, $msg){
    // 需要注意的是，这里不能复用外部redis的连接，因为redis连接会被下面的psubcript占用，导致不可用
    // 这里注意要用try—catch捕获异常，不然出错就会导致服务不可用
    try {
        $redis2 = redis_conn();
        // 这里的重点是，在设置键的时候，要注意，保存数据的键要比监听的键ttl时间长一点
        // 而且要注意判断key和值
        // 这里搞成事件监听，方便一点
    }catch (\Throwable $th){
    
    }finally {
       // do something ...
    }
};
// 这里相当于是订阅了这个库里面的键消失，然后就会触发call_back这个方法
$redis->psubscript([
    '__keyevent@' . select1 . '__:expired',
    '__keyevent@' . select1 . '__:del',
],$call_back);
```


### id_pool redis简单版
```text
本质： 不让他id自增，让直接冲id池里面取
目的： 一个完整的数据被拆分装到多张表里，关联是其中的某一张表的自增id
```
看下代码
```php
<?php
// 关键代码就一句，避免高并发取到同一个id
// https://redis.io/commands/blpop/
$res = (new \Redis)->connect('127.0.0.1')->blpop($key);

// 其他的设计无非就是，workerman 定时任务跑一跑id池剩余的id，然后达不到预期就rpop为开始，生成一批
```

# 在项目中的应用：
原来一个qps不到10的接口，现在要改造成qps >= 100

## 前置操作
经过对这个接口每个步骤的执行时间进行输出，发现，瓶颈在数据库 i/o上  
于是用异步的方式写入，减少数据库I/O;  存储在redis的键空间里面，然后写入

## 实操
用同事实现的日志记录的键空间代码，查看逻辑，是分别写一个主key，然后面一个存值的副key，以及另一个副key是存事件回调的方法名  
然后一直往里面push，监听和过滤这个主key，获取存值的副key，然后写入。  


## 遇到的问题
用同事提供的代码，发现总是会多写入好几条数据。
原因：   
然后我发现他是判断副key是否存在，然后往里面写数据。但是这个时候就会造成一个问题就是，主key消失了，但是副key是存数据的，ttl
会延后1-2秒，就会导致一个时间差，导致多写入几条。 因为主key和副key是的名字有关联关系  


## 改造
因为以前都是每次都用的同一个key  
然后现在正在key上面加了个时间戳，每次的key都不一样了  

[问题又来了] 这个时候 又会导致少写入几条，为什么呢？ 因为存数据选的redis数据类型不对
```php
// 部分代码
// 伪代码

data = param; // 要存的数据
save_data = redis->get(save_data_key);
if(save_data){
    save_data = json_decode(save_data,true);
    save_data = array_merge(save_data,data);
    save_data = json_encode(save_data);
}

redis->set(save_data_key,save_data);

```
为什么会产生这个问题呢？ 因为数据来的时候，这一秒的key还存在，然后取值并合并的过程中，这个key就过期了，所以导致 ，会少几条数据

## 改造2
换个数据结构，没有取值解析再合并再写入的过程，直接写入， 现在是用的hashtable
  这样的话，写入数据库之前，需要对每条数据解一下json然后批量写入

# id池的应用
TODO